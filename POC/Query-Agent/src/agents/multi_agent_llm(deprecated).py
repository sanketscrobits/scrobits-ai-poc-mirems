from langgraph.graph import StateGraph, START, END
from langchain_google_genai import ChatGoogleGenerativeAI
from typing import TypedDict, Literal
from src.agents.retriver_agent import create_query_agent
from pydantic import BaseModel, Field
from settings import GOOGLE_API_KEY


model = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    google_api_key=GOOGLE_API_KEY
)
query_agent = create_query_agent(api_key= GOOGLE_API_KEY)

class LlmSchema(BaseModel):

    verification: Literal["yes", "no"] = Field(description='relation between the user query and the response by llm')

class ResponseSchema(TypedDict):
    user_query: str
    query_response: str
    evaluation_state: Literal["pass", "fail"]


def retriver_agent(state: ResponseSchema) -> ResponseSchema:
    user_query = state["user_query"]
    result = query_agent.invoke({"input": user_query})["output"]

    return {
        "user_query": user_query,
        "query_response": result,
        "evaluation_state": "pending"
    }

def evaluator_agent(state: ResponseSchema) -> ResponseSchema:
    
    user_query = state["user_query"]
    query_response = state["query_response"]

    structured_model = model.with_structured_output(LlmSchema)

    prompt = f"""You are a support assistant who is capable of excellent evaluation.
    The llm had generated this response '{query_response}' based on the user query `{user_query}`. reply with just one word "yes" or "no", depending upon the match of the user query and the response generated by the llm, with the profanity words if there are any.
    """
    validation = structured_model.invoke(prompt).verification

    evaluation_state = "pass" if validation.lower() == "yes" else "fail"

    return {
        "user_query": user_query,
        "query_response": query_response,
        "evaluation_state": evaluation_state
    }

graph = StateGraph(ResponseSchema)

graph.add_node('retriver_agent', retriver_agent)
graph.add_node('evaluator_agent', evaluator_agent)

graph.add_edge(START, 'retriver_agent')
graph.add_edge('retriver_agent', 'evaluator_agent')
graph.add_edge('evaluator_agent', END)

workflow = graph.compile()

initial_state = {
    "user_query": "What trend did Statistics Canada report about electric vehicle sales in Q2 2025?",
    "query_response": "",
    "evaluation_state": "pending"
}

final_state = workflow.invoke(initial_state, config={"verbose": True})

print(final_state)
