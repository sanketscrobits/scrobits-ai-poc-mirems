from langgraph.graph import StateGraph, START, END
from langchain_google_genai import ChatGoogleGenerativeAI
from typing import TypedDict, Literal
from src.agents.retriver_agent import create_query_agent
from pydantic import BaseModel, Field
from settings import GOOGLE_API_KEY


model = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
query_agent = create_query_agent(GOOGLE_API_KEY)

class LlmSchema(BaseModel):

    verification: Literal["yes", "no"] = Field(description='relation between the user query and the response by llm')

class ResponseSchema(TypedDict):
    user_query: str
    query_response: str
    evaluation_state: Literal["pass", "fail"]


def retriver_agent(state: ResponseSchema) -> ResponseSchema:
    user_query = state["user_query"]
    result = query_agent.invoke({"input": user_query})

    return {"query_response" :result}

def evaluator_agent(state: ResponseSchema) -> ResponseSchema:
    
    user_query = state["user_query"]
    query_response = state["query_response"]

    structured_model = model.with_structured_output(LlmSchema)

    prompt = f"""You are a support assistant who is capable of excellent evaluation.
    The llm had generated this response '{query_response}' based on the user query `{user_query}`. reply with just one word "yes" or "no", depending upon the match of the user query and the response generated by the llm
    """
    validation = structured_model.invoke(prompt).verification
    print(validation)

graph = StateGraph(ResponseSchema)

graph.add_node('retriver_agent', retriver_agent)
graph.add_node('evaluator_agent', evaluator_agent)

graph.add_edge(START, 'retriver_agent')
graph.add_edge('retriver_agent', 'evaluator_agent')
graph.add_edge('evaluator_agent', END)

workflow = graph.compile()

initial_state = {'user_query':'What trend did Statistics Canada report about electric vehicle sales in Q2 2025?'}

final_state = workflow.invoke(initial_state, config={"verbose": True})

print(final_state)
